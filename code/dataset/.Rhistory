}
for (required_package in required_packages) {
require(required_package, character.only = T)
library(required_package, character.only = T)
}
### Read the dataset ###
dataset = read_dataset('datasets/bank', 'data.csv', ';')
categorical_columns = c(1, 3:11, 16);
### Pre-process the dataset ###
dataset = remove_attributes_with_single_values(dataset)
for (numeric_attribute in colnames(dataset[, -categorical_columns])) {
plot(density(dataset[, numeric_attribute]), main = numeric_attribute)
}
boolean_dataset = convert_to_boolean_attributes(dataset, categorical_columns)
# Ignore the first "boolean"ized output variable.
boolean_dataset = boolean_dataset[, -1]
boolean_dataset = remove_attributes_with_high_correlation(
boolean_dataset, threshold = 0.99)
boolean_dataset = remove_attributes_with_low_output_correlation(
boolean_dataset, threshold = 0.01)
cat("Final set of attributes = ", colnames(boolean_dataset), "\n")
cat("Final number of attributes = ", ncol(boolean_dataset), "\n")
# Scale the attributes (except for the class attribute)
boolean_dataset[, -1] = scale(boolean_dataset[, -1], center = T, scale = T)
### Run the classifiers ###
cat("Running the classifiers...\n")
#for (run in 1:5) {
#cat("Run Number", run, "\n\n")
training_rows = sample_rows(nrow(dataset), split = 0.8)
training_dataset = dataset[training_rows,]
test_dataset = dataset[-training_rows,]
training_boolean_dataset = boolean_dataset[training_rows,]
test_boolean_dataset = boolean_dataset[-training_rows,]
cat(colnames(training_dataset)[1])
cat(colnames(training_boolean_dataset)[1])
# Run and evaluate the logistic regression classifier.
evaluate_logistic_regression(training_boolean_dataset, test_boolean_dataset)
#}
source('classifier_utils.R')
### Install and load required packages ###
required_packages = c("ade4", # for converting categorical to bool attributes
"corrplot", # for computing and plotting correlations
"rpart", # for decision trees
"neuralnet", # for neural net
"e1071", # for SVM and Naive Bayes
"AUC", # for computing auc(roc)
"cvTools", # for cross validation
"stats", # logistic regression
"class" )# knn
missing_packages =
required_packages[!(required_packages %in% installed.packages()[,"Package"])]
if(length(missing_packages)) {
install.packages(missing_packages)
}
for (required_package in required_packages) {
require(required_package, character.only = T)
library(required_package, character.only = T)
}
### Read the dataset ###
dataset = read_dataset('datasets/bank', 'data.csv', ';')
categorical_columns = c(1, 3:11, 16);
### Pre-process the dataset ###
dataset = remove_attributes_with_single_values(dataset)
for (numeric_attribute in colnames(dataset[, -categorical_columns])) {
plot(density(dataset[, numeric_attribute]), main = numeric_attribute)
}
boolean_dataset = convert_to_boolean_attributes(dataset, categorical_columns)
# Ignore the first "boolean"ized output variable.
boolean_dataset = boolean_dataset[, -1]
boolean_dataset = remove_attributes_with_high_correlation(
boolean_dataset, threshold = 0.99)
boolean_dataset = remove_attributes_with_low_output_correlation(
boolean_dataset, threshold = 0.01)
cat("Final set of attributes = ", colnames(boolean_dataset), "\n")
cat("Final number of attributes = ", ncol(boolean_dataset), "\n")
# Scale the attributes (except for the class attribute)
boolean_dataset[, -1] = scale(boolean_dataset[, -1], center = T, scale = T)
### Run the classifiers ###
cat("Running the classifiers...\n")
#for (run in 1:5) {
#cat("Run Number", run, "\n\n")
training_rows = sample_rows(nrow(dataset), split = 0.8)
training_dataset = dataset[training_rows,]
test_dataset = dataset[-training_rows,]
training_boolean_dataset = boolean_dataset[training_rows,]
test_boolean_dataset = boolean_dataset[-training_rows,]
cat(colnames(training_dataset)[1])
cat(colnames(training_boolean_dataset)[1])
# Run and evaluate the logistic regression classifier.
evaluate_logistic_regression(training_boolean_dataset, test_boolean_dataset)
#}
source('classifier_utils.R')
### Install and load required packages ###
required_packages = c("ade4", # for converting categorical to bool attributes
"corrplot", # for computing and plotting correlations
"rpart", # for decision trees
"neuralnet", # for neural net
"e1071", # for SVM and Naive Bayes
"AUC", # for computing auc(roc)
"cvTools", # for cross validation
"stats", # logistic regression
"class" )# knn
missing_packages =
required_packages[!(required_packages %in% installed.packages()[,"Package"])]
if(length(missing_packages)) {
install.packages(missing_packages)
}
for (required_package in required_packages) {
require(required_package, character.only = T)
library(required_package, character.only = T)
}
### Read the dataset ###
dataset = read_dataset('datasets/bank', 'data.csv', ';')
categorical_columns = c(1, 3:11, 16);
### Pre-process the dataset ###
dataset = remove_attributes_with_single_values(dataset)
for (numeric_attribute in colnames(dataset[, -categorical_columns])) {
plot(density(dataset[, numeric_attribute]), main = numeric_attribute)
}
boolean_dataset = convert_to_boolean_attributes(dataset, categorical_columns)
# Ignore the first "boolean"ized output variable.
boolean_dataset = boolean_dataset[, -1]
boolean_dataset = remove_attributes_with_high_correlation(
boolean_dataset, threshold = 0.99)
boolean_dataset = remove_attributes_with_low_output_correlation(
boolean_dataset, threshold = 0.01)
cat("Final set of attributes = ", colnames(boolean_dataset), "\n")
cat("Final number of attributes = ", ncol(boolean_dataset), "\n")
# Scale the attributes (except for the class attribute)
boolean_dataset[, -1] = scale(boolean_dataset[, -1], center = T, scale = T)
### Run the classifiers ###
cat("Running the classifiers...\n")
#for (run in 1:5) {
#cat("Run Number", run, "\n\n")
training_rows = sample_rows(nrow(dataset), split = 0.8)
training_dataset = dataset[training_rows,]
test_dataset = dataset[-training_rows,]
training_boolean_dataset = boolean_dataset[training_rows,]
test_boolean_dataset = boolean_dataset[-training_rows,]
cat(colnames(training_dataset)[1])
cat(colnames(training_boolean_dataset)[1])
# Run and evaluate the logistic regression classifier.
evaluate_logistic_regression(training_boolean_dataset, test_boolean_dataset)
#}
source('classifier_utils.R')
### Install and load required packages ###
required_packages = c("ade4", # for converting categorical to bool attributes
"corrplot", # for computing and plotting correlations
"rpart", # for decision trees
"neuralnet", # for neural net
"e1071", # for SVM and Naive Bayes
"AUC", # for computing auc(roc)
"cvTools", # for cross validation
"stats", # logistic regression
"class" )# knn
missing_packages =
required_packages[!(required_packages %in% installed.packages()[,"Package"])]
if(length(missing_packages)) {
install.packages(missing_packages)
}
for (required_package in required_packages) {
require(required_package, character.only = T)
library(required_package, character.only = T)
}
### Read the dataset ###
dataset = read_dataset('datasets/bank', 'data.csv', ';')
categorical_columns = c(1, 3:11, 16);
### Pre-process the dataset ###
dataset = remove_attributes_with_single_values(dataset)
for (numeric_attribute in colnames(dataset[, -categorical_columns])) {
plot(density(dataset[, numeric_attribute]), main = numeric_attribute)
}
boolean_dataset = convert_to_boolean_attributes(dataset, categorical_columns)
# Ignore the first "boolean"ized output variable.
boolean_dataset = boolean_dataset[, -1]
boolean_dataset = remove_attributes_with_high_correlation(
boolean_dataset, threshold = 0.99)
boolean_dataset = remove_attributes_with_low_output_correlation(
boolean_dataset, threshold = 0.01)
cat("Final set of attributes = ", colnames(boolean_dataset), "\n")
cat("Final number of attributes = ", ncol(boolean_dataset), "\n")
# Scale the attributes (except for the class attribute)
boolean_dataset[, -1] = scale(boolean_dataset[, -1], center = T, scale = T)
### Run the classifiers ###
cat("Running the classifiers...\n")
#for (run in 1:5) {
#cat("Run Number", run, "\n\n")
training_rows = sample_rows(nrow(dataset), split = 0.8)
training_dataset = dataset[training_rows,]
test_dataset = dataset[-training_rows,]
training_boolean_dataset = boolean_dataset[training_rows,]
test_boolean_dataset = boolean_dataset[-training_rows,]
cat(colnames(training_dataset)[1])
cat(colnames(training_boolean_dataset)[1])
# Run and evaluate the logistic regression classifier.
evaluate_logistic_regression(training_boolean_dataset, test_boolean_dataset)
#}
source('classifier_utils.R')
### Install and load required packages ###
required_packages = c("ade4", # for converting categorical to bool attributes
"corrplot", # for computing and plotting correlations
"rpart", # for decision trees
"neuralnet", # for neural net
"e1071", # for SVM and Naive Bayes
"AUC", # for computing auc(roc)
"cvTools", # for cross validation
"stats", # logistic regression
"class" )# knn
missing_packages =
required_packages[!(required_packages %in% installed.packages()[,"Package"])]
if(length(missing_packages)) {
install.packages(missing_packages)
}
for (required_package in required_packages) {
require(required_package, character.only = T)
library(required_package, character.only = T)
}
### Read the dataset ###
dataset = read_dataset('datasets/bank', 'data.csv', ';')
categorical_columns = c(1, 3:11, 16);
### Pre-process the dataset ###
dataset = remove_attributes_with_single_values(dataset)
for (numeric_attribute in colnames(dataset[, -categorical_columns])) {
plot(density(dataset[, numeric_attribute]), main = numeric_attribute)
}
boolean_dataset = convert_to_boolean_attributes(dataset, categorical_columns)
# Ignore the first "boolean"ized output variable.
boolean_dataset = boolean_dataset[, -1]
boolean_dataset = remove_attributes_with_high_correlation(
boolean_dataset, threshold = 0.99)
boolean_dataset = remove_attributes_with_low_output_correlation(
boolean_dataset, threshold = 0.01)
cat("Final set of attributes = ", colnames(boolean_dataset), "\n")
cat("Final number of attributes = ", ncol(boolean_dataset), "\n")
# Scale the attributes (except for the class attribute)
boolean_dataset[, -1] = scale(boolean_dataset[, -1], center = T, scale = T)
### Run the classifiers ###
cat("Running the classifiers...\n")
#for (run in 1:5) {
#cat("Run Number", run, "\n\n")
training_rows = sample_rows(nrow(dataset), split = 0.8)
training_dataset = dataset[training_rows,]
test_dataset = dataset[-training_rows,]
training_boolean_dataset = boolean_dataset[training_rows,]
test_boolean_dataset = boolean_dataset[-training_rows,]
cat(colnames(training_dataset)[1])
cat(colnames(training_boolean_dataset)[1])
# Run and evaluate the logistic regression classifier.
evaluate_logistic_regression(training_boolean_dataset, test_boolean_dataset)
#}
source('classifier_utils.R')
### Install and load required packages ###
required_packages = c("ade4", # for converting categorical to bool attributes
"corrplot", # for computing and plotting correlations
"rpart", # for decision trees
"neuralnet", # for neural net
"e1071", # for SVM and Naive Bayes
"AUC", # for computing auc(roc)
"cvTools", # for cross validation
"stats", # logistic regression
"class" )# knn
missing_packages =
required_packages[!(required_packages %in% installed.packages()[,"Package"])]
if(length(missing_packages)) {
install.packages(missing_packages)
}
for (required_package in required_packages) {
require(required_package, character.only = T)
library(required_package, character.only = T)
}
### Read the dataset ###
dataset = read_dataset('datasets/bank', 'data.csv', ';')
categorical_columns = c(1, 3:11, 16);
### Pre-process the dataset ###
dataset = remove_attributes_with_single_values(dataset)
for (numeric_attribute in colnames(dataset[, -categorical_columns])) {
plot(density(dataset[, numeric_attribute]), main = numeric_attribute)
}
boolean_dataset = convert_to_boolean_attributes(dataset, categorical_columns)
# Ignore the first "boolean"ized output variable.
boolean_dataset = boolean_dataset[, -1]
boolean_dataset = remove_attributes_with_high_correlation(
boolean_dataset, threshold = 0.99)
boolean_dataset = remove_attributes_with_low_output_correlation(
boolean_dataset, threshold = 0.01)
cat("Final set of attributes = ", colnames(boolean_dataset), "\n")
cat("Final number of attributes = ", ncol(boolean_dataset), "\n")
# Scale the attributes (except for the class attribute)
boolean_dataset[, -1] = scale(boolean_dataset[, -1], center = T, scale = T)
### Run the classifiers ###
cat("Running the classifiers...\n")
#for (run in 1:5) {
#cat("Run Number", run, "\n\n")
training_rows = sample_rows(nrow(dataset), split = 0.8)
training_dataset = dataset[training_rows,]
test_dataset = dataset[-training_rows,]
training_boolean_dataset = boolean_dataset[training_rows,]
test_boolean_dataset = boolean_dataset[-training_rows,]
cat(colnames(training_dataset)[1])
cat(colnames(training_boolean_dataset)[1])
# Run and evaluate the logistic regression classifier.
evaluate_logistic_regression(training_boolean_dataset, test_boolean_dataset)
#}
source('classifier_utils.R')
### Install and load required packages ###
required_packages = c("ade4", # for converting categorical to bool attributes
"corrplot", # for computing and plotting correlations
"rpart", # for decision trees
"neuralnet", # for neural net
"e1071", # for SVM and Naive Bayes
"AUC", # for computing auc(roc)
"cvTools", # for cross validation
"stats", # logistic regression
"class" )# knn
missing_packages =
required_packages[!(required_packages %in% installed.packages()[,"Package"])]
if(length(missing_packages)) {
install.packages(missing_packages)
}
for (required_package in required_packages) {
require(required_package, character.only = T)
library(required_package, character.only = T)
}
### Read the dataset ###
dataset = read_dataset('datasets/bank', 'data.csv', ';')
categorical_columns = c(1, 3:11, 16);
### Pre-process the dataset ###
dataset = remove_attributes_with_single_values(dataset)
for (numeric_attribute in colnames(dataset[, -categorical_columns])) {
plot(density(dataset[, numeric_attribute]), main = numeric_attribute)
}
boolean_dataset = convert_to_boolean_attributes(dataset, categorical_columns)
# Ignore the first "boolean"ized output variable.
boolean_dataset = boolean_dataset[, -1]
boolean_dataset = remove_attributes_with_high_correlation(
boolean_dataset, threshold = 0.99)
boolean_dataset = remove_attributes_with_low_output_correlation(
boolean_dataset, threshold = 0.01)
cat("Final set of attributes = ", colnames(boolean_dataset), "\n")
cat("Final number of attributes = ", ncol(boolean_dataset), "\n")
# Scale the attributes (except for the class attribute)
boolean_dataset[, -1] = scale(boolean_dataset[, -1], center = T, scale = T)
### Run the classifiers ###
cat("Running the classifiers...\n")
#for (run in 1:5) {
#cat("Run Number", run, "\n\n")
training_rows = sample_rows(nrow(dataset), split = 0.8)
training_dataset = dataset[training_rows,]
test_dataset = dataset[-training_rows,]
training_boolean_dataset = boolean_dataset[training_rows,]
test_boolean_dataset = boolean_dataset[-training_rows,]
cat(colnames(training_dataset)[1])
cat(colnames(training_boolean_dataset)[1])
# Run and evaluate the logistic regression classifier.
evaluate_logistic_regression(training_boolean_dataset, test_boolean_dataset)
#}
source('classifier_utils.R')
### Install and load required packages ###
required_packages = c("ade4", # for converting categorical to bool attributes
"corrplot", # for computing and plotting correlations
"rpart", # for decision trees
"neuralnet", # for neural net
"e1071", # for SVM and Naive Bayes
"AUC", # for computing auc(roc)
"cvTools", # for cross validation
"stats", # logistic regression
"class" )# knn
missing_packages =
required_packages[!(required_packages %in% installed.packages()[,"Package"])]
if(length(missing_packages)) {
install.packages(missing_packages)
}
for (required_package in required_packages) {
require(required_package, character.only = T)
library(required_package, character.only = T)
}
### Read the dataset ###
dataset = read_dataset('datasets/bank', 'data.csv', ';')
categorical_columns = c(1, 3:11, 16);
### Pre-process the dataset ###
dataset = remove_attributes_with_single_values(dataset)
for (numeric_attribute in colnames(dataset[, -categorical_columns])) {
plot(density(dataset[, numeric_attribute]), main = numeric_attribute)
}
boolean_dataset = convert_to_boolean_attributes(dataset, categorical_columns)
# Ignore the first "boolean"ized output variable.
boolean_dataset = boolean_dataset[, -1]
boolean_dataset = remove_attributes_with_high_correlation(
boolean_dataset, threshold = 0.99)
boolean_dataset = remove_attributes_with_low_output_correlation(
boolean_dataset, threshold = 0.01)
cat("Final set of attributes = ", colnames(boolean_dataset), "\n")
cat("Final number of attributes = ", ncol(boolean_dataset), "\n")
# Scale the attributes (except for the class attribute)
boolean_dataset[, -1] = scale(boolean_dataset[, -1], center = T, scale = T)
### Run the classifiers ###
cat("Running the classifiers...\n")
#for (run in 1:5) {
#cat("Run Number", run, "\n\n")
training_rows = sample_rows(nrow(dataset), split = 0.8)
training_dataset = dataset[training_rows,]
test_dataset = dataset[-training_rows,]
training_boolean_dataset = boolean_dataset[training_rows,]
test_boolean_dataset = boolean_dataset[-training_rows,]
cat(colnames(training_dataset)[1])
cat(colnames(training_boolean_dataset)[1])
# Run and evaluate the logistic regression classifier.
evaluate_logistic_regression(training_boolean_dataset, test_boolean_dataset)
#}
source('classifier_utils.R')
### Install and load required packages ###
required_packages = c("ade4", # for converting categorical to bool attributes
"corrplot", # for computing and plotting correlations
"rpart", # for decision trees
"neuralnet", # for neural net
"e1071", # for SVM and Naive Bayes
"AUC", # for computing auc(roc)
"cvTools", # for cross validation
"stats", # logistic regression
"class" )# knn
missing_packages =
required_packages[!(required_packages %in% installed.packages()[,"Package"])]
if(length(missing_packages)) {
install.packages(missing_packages)
}
for (required_package in required_packages) {
require(required_package, character.only = T)
library(required_package, character.only = T)
}
### Read the dataset ###
dataset = read_dataset('datasets/bank', 'data.csv', ';')
categorical_columns = c(1, 3:11, 16);
### Pre-process the dataset ###
dataset = remove_attributes_with_single_values(dataset)
for (numeric_attribute in colnames(dataset[, -categorical_columns])) {
plot(density(dataset[, numeric_attribute]), main = numeric_attribute)
}
boolean_dataset = convert_to_boolean_attributes(dataset, categorical_columns)
# Ignore the first "boolean"ized output variable.
boolean_dataset = boolean_dataset[, -1]
boolean_dataset = remove_attributes_with_high_correlation(
boolean_dataset, threshold = 0.99)
boolean_dataset = remove_attributes_with_low_output_correlation(
boolean_dataset, threshold = 0.01)
cat("Final set of attributes = ", colnames(boolean_dataset), "\n")
cat("Final number of attributes = ", ncol(boolean_dataset), "\n")
# Scale the attributes (except for the class attribute)
boolean_dataset[, -1] = scale(boolean_dataset[, -1], center = T, scale = T)
### Run the classifiers ###
cat("Running the classifiers...\n")
#for (run in 1:5) {
#cat("Run Number", run, "\n\n")
training_rows = sample_rows(nrow(dataset), split = 0.8)
training_dataset = dataset[training_rows,]
test_dataset = dataset[-training_rows,]
training_boolean_dataset = boolean_dataset[training_rows,]
test_boolean_dataset = boolean_dataset[-training_rows,]
cat(colnames(training_dataset)[1])
cat(colnames(training_boolean_dataset)[1])
# Run and evaluate the logistic regression classifier.
evaluate_logistic_regression(training_boolean_dataset, test_boolean_dataset)
#}
setwd("C:/Users/hemac/Desktop/mlproject")
library(mlbench)
install.packages(missing_packages)
install.packages(mlbench)
install.packages("crandatapkgs")
library(mlbench)
install.packages(mlbench)
install.packages("mlbench")
dat <- read.csv('dataset', 'train.csv',',')
setwd("C:/Users/hemac/Desktop/mlproject/dataset")
dat <- read.csv(train.csv',',')
dat <- read.csv('train.csv',',')
dat <- read.csv('train.csv')
summary(dat$SalePrice)
data <- read.csv(iris)
housing <- read.table(housing)
housing <- read.table('housing.data')
summary(housing)
summary(housing[,length(housing[1])])
summary(housing[,length(housing[1]) - 1])
summary(dat)
nnet.fit <- nnet(medv/50 ~ ., data=BostonHousing, size=2)
nnet.fit <- nnet(SalePrice/755000 ~ ., data=dat, size=2)
library(mlbench)
nnet.fit <- nnet(SalePrice/755000 ~ ., data=dat, size=2)
nnet.fit <- nnet(SalePrice/755000 ~ ., data=dat, size=2)
require(nnet)
nnet.fit <- nnet(SalePrice/755000 ~ ., data=dat, size=2)
nnet.fit <- nnet(SalePrice/755000 ~ ., data=dat, size=2)
predict(nnet.fit) * 755000
plot(dat$SalePrice, nnet.predict,
main="Neural network predictions vs actual",
xlab="Actual")
nnet.predict <- predict(nnet.fit) * 755000
plot(dat$SalePrice, nnet.predict,
main="Neural network predictions vs actual",
xlab="Actual")
length(dat$SalePrice)
length(nnet.predict)
nnet.fit <- nnet(SalePrice/755000 ~ ., data=dat)
nnet.fit <- nnet(SalePrice/755000 ~ ., data=dat)
library(mlbench)
require(caret)
install.packages("caret")
library(caret)
nnetfit <- train(medv/50 ~ ., data=BostonHousing, method="nnet", maxit=1000, tuneGrid=mygrid, trace=F)
> print(nnetfit)
nnetfit <- train(SalePrice/50 ~ ., data=dat, method="nnet", maxit=1000, trace=F)
nnetfit <- train(SalePrice/755000 ~ ., data=dat, method="nnet", maxit=1000, trace=F)
nnetfit <- train(dat$SalePrice/755000 ~ ., data=dat, method="nnet", maxit=1000, trace=F)
